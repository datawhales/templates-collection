{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 13:04:32.384800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(batch_size, 64, input_length=30),\n",
    "    Flatten(),\n",
    "    Dense(3, activation=\"relu\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f907b002850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 30, 64)            2048      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1920)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 5763      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,811\n",
      "Trainable params: 7,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 30), dtype=float32, numpy=\n",
       "array([[0.8961592 , 0.18652117, 0.00308526, ..., 0.3928566 , 0.894282  ,\n",
       "        0.15054286],\n",
       "       [0.85607374, 0.26575303, 0.62575126, ..., 0.7796391 , 0.4155941 ,\n",
       "        0.64770055],\n",
       "       [0.55605483, 0.32109237, 0.78327537, ..., 0.94200635, 0.25302327,\n",
       "        0.01880991],\n",
       "       ...,\n",
       "       [0.65683067, 0.12700498, 0.31996942, ..., 0.96840215, 0.05286002,\n",
       "        0.3504702 ],\n",
       "       [0.54818857, 0.10560656, 0.5492163 , ..., 0.03055632, 0.17665696,\n",
       "        0.24453807],\n",
       "       [0.5661417 , 0.07087457, 0.909546  , ..., 0.1905855 , 0.40099382,\n",
       "        0.768927  ]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape=[128, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = tf.random.uniform(shape=[128, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 3), dtype=float32, numpy=\n",
       "array([[0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256],\n",
       "       [0.        , 0.02592088, 0.01417256]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 30)\n",
      "(128, 30, 64)\n",
      "(128, 1920)\n",
      "(128, 3)\n"
     ]
    }
   ],
   "source": [
    "sample_tensor = tf.random.uniform(shape=[128, 30])\n",
    "layer_1 = Embedding(32, 64, input_length=30)\n",
    "layer_2 = Flatten()\n",
    "layer_3 = Dense(3, activation=\"relu\")\n",
    "x = layer_1(sample_tensor)\n",
    "y = layer_2(x)\n",
    "z = layer_3(y)\n",
    "\n",
    "print(sample_tensor.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = Embedding(32, 64, input_length=30)\n",
    "layer_2 = Flatten()\n",
    "layer_3 = Dense(3, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 30, 64), dtype=float32, numpy=\n",
       "array([[[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1(sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layer_1(sample_tensor)\n",
    "y = layer_2(x)\n",
    "z = layer_3(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 30, 64), dtype=float32, numpy=\n",
       "array([[[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]],\n",
       "\n",
       "       [[-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        ...,\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498],\n",
       "        [-0.02036272, -0.0237268 ,  0.00631499, ..., -0.02310616,\n",
       "         -0.02643397,  0.01442498]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.03418969  0.04032305 -0.03208804 -0.01132747]\n",
      "  [ 0.00268213  0.03741105  0.04512442  0.03014264]\n",
      "  [ 0.03664098  0.01156452  0.02550048 -0.00318028]\n",
      "  [-0.00337983 -0.02752945  0.02263576 -0.01412369]\n",
      "  [ 0.01858387  0.00604148  0.03327641 -0.02246153]]], shape=(1, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the input sequence as a list of integers\n",
    "input_sequence = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Define the vocabulary size and embedding dimension\n",
    "vocab_size = 10\n",
    "embedding_dim = 4\n",
    "\n",
    "# Create the Embedding layer\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                             output_dim=embedding_dim,\n",
    "                                             input_length=len(input_sequence))\n",
    "\n",
    "# Convert the input sequence into a tensor\n",
    "input_tensor = tf.constant([input_sequence])\n",
    "\n",
    "# Apply the Embedding layer to the input tensor\n",
    "output_tensor = embedding_layer(input_tensor)\n",
    "\n",
    "# Print the output tensor\n",
    "print(output_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 5, 4)              40        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Sequential([embedding_layer]).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.01662654  0.02190778 -0.01608838  0.02065922]\n",
      "  [-0.04036766 -0.04143571  0.03835041  0.02209977]\n",
      "  [-0.04490414  0.00259271  0.04704073  0.0349595 ]\n",
      "  [ 0.03535949  0.01210357  0.02231849 -0.04862317]\n",
      "  [-0.0451902   0.0126653  -0.04824703  0.00698972]]], shape=(1, 5, 4), dtype=float32)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 5, 4)              80        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the input sequence as a list of integers\n",
    "input_sequence = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Define the vocabulary size and embedding dimension\n",
    "vocab_size = 20\n",
    "embedding_dim = 4\n",
    "\n",
    "# Create the Embedding layer\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                             output_dim=embedding_dim,\n",
    "                                             input_length=len(input_sequence))\n",
    "\n",
    "# Convert the input sequence into a tensor\n",
    "input_tensor = tf.constant([input_sequence])\n",
    "\n",
    "# Apply the Embedding layer to the input tensor\n",
    "output_tensor = embedding_layer(input_tensor)\n",
    "\n",
    "# Print the output tensor\n",
    "print(output_tensor)\n",
    "\n",
    "Sequential([embedding_layer]).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.02090628 -0.00707681  0.01176493 -0.04236705]\n",
      "  [-0.04514579  0.03301262 -0.04939482 -0.03017534]\n",
      "  [-0.0364027  -0.03103849  0.00979775 -0.0412675 ]\n",
      "  [ 0.01443014  0.03965732  0.04189073  0.04499013]\n",
      "  [ 0.00147795 -0.00783066 -0.01002204 -0.02299225]]], shape=(1, 5, 4), dtype=float32)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 5, 4)              24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the input sequence as a list of integers\n",
    "input_sequence = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Define the vocabulary size and embedding dimension\n",
    "vocab_size = 6\n",
    "embedding_dim = 4\n",
    "\n",
    "# Create the Embedding layer\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                             output_dim=embedding_dim,\n",
    "                                             input_length=len(input_sequence))\n",
    "\n",
    "# Convert the input sequence into a tensor\n",
    "input_tensor = tf.constant([input_sequence])\n",
    "\n",
    "# Apply the Embedding layer to the input tensor\n",
    "output_tensor = embedding_layer(input_tensor)\n",
    "\n",
    "# Print the output tensor\n",
    "print(output_tensor)\n",
    "\n",
    "Sequential([embedding_layer]).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.0010475  -0.0382571  -0.03895509 -0.01551219]\n",
      "  [-0.01688478  0.01388098  0.03693408 -0.00888158]\n",
      "  [-0.01171356  0.01665914 -0.03428346  0.03826653]\n",
      "  [-0.04147266 -0.01506538 -0.03454428 -0.00795183]\n",
      "  [ 0.02516628  0.04580224 -0.01796976  0.01137583]]\n",
      "\n",
      " [[ 0.01933844 -0.02477287 -0.02668176  0.00887012]\n",
      "  [-0.04722112 -0.02435671  0.00215621  0.02494004]\n",
      "  [ 0.03064785  0.02114118 -0.02324005 -0.0446303 ]\n",
      "  [-0.00400505  0.00574537 -0.02762654 -0.00503178]\n",
      "  [-0.04745935 -0.00196664  0.00296607 -0.04356611]]], shape=(2, 5, 4), dtype=float32)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 5, 4)              80        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the input sequence as a list of integers\n",
    "input_sequence = [[1, 2, 3, 4, 5], [6,7,8,9,10]]\n",
    "\n",
    "# Define the vocabulary size and embedding dimension\n",
    "vocab_size = 20\n",
    "embedding_dim = 4\n",
    "\n",
    "# Create the Embedding layer\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                             output_dim=embedding_dim,\n",
    "                                             input_length=len(input_sequence[0]))\n",
    "\n",
    "# Convert the input sequence into a tensor\n",
    "input_tensor = tf.constant(input_sequence)\n",
    "\n",
    "# Apply the Embedding layer to the input tensor\n",
    "output_tensor = embedding_layer(input_tensor)\n",
    "\n",
    "# Print the output tensor\n",
    "print(output_tensor)\n",
    "\n",
    "Sequential([embedding_layer]).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.randint(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "a = tf.constant([1, 2, 3, 4, 5])\n",
    "\n",
    "input_layer = Input(shape=(5, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,112\n",
      "Trainable params: 2,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the shape of the input tensor\n",
    "input_shape = (32,)\n",
    "\n",
    "# Create the Input layer\n",
    "input_layer = tf.keras.layers.Input(shape=input_shape, dtype=tf.float32)\n",
    "\n",
    "# Create another layer that takes the input layer as input\n",
    "hidden_layer = tf.keras.layers.Dense(units=64, activation='relu')(input_layer)\n",
    "\n",
    "# Create the model by specifying the input and output layers\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=hidden_layer)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,112\n",
      "Trainable params: 2,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the shape of the input tensor\n",
    "input_shape = (32,)\n",
    "\n",
    "# Create the Input layer\n",
    "input_layer = tf.keras.layers.Input(shape=input_shape, dtype=tf.float32)\n",
    "\n",
    "# Create another layer that takes the input layer as input\n",
    "hidden_layer = tf.keras.layers.Dense(units=64, activation='relu')(input_layer)\n",
    "\n",
    "# Create the model by specifying the input and output layers\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=hidden_layer)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = tf.random.uniform(shape=[8, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 32), dtype=float32, numpy=\n",
       "array([[0.46945286, 0.03017509, 0.7259394 , 0.67181575, 0.27654254,\n",
       "        0.9235605 , 0.4704144 , 0.95845866, 0.61214495, 0.4619323 ,\n",
       "        0.13269877, 0.41948402, 0.03550673, 0.09371161, 0.39704573,\n",
       "        0.47702658, 0.7882478 , 0.44684517, 0.96381545, 0.22317386,\n",
       "        0.48420715, 0.84791195, 0.6141523 , 0.48651338, 0.17182434,\n",
       "        0.96939397, 0.7418438 , 0.3506732 , 0.7388313 , 0.6904324 ,\n",
       "        0.03845024, 0.8472487 ],\n",
       "       [0.01249492, 0.28553033, 0.2286756 , 0.02653444, 0.5106282 ,\n",
       "        0.67817473, 0.03488922, 0.1829822 , 0.2301122 , 0.7975955 ,\n",
       "        0.95897543, 0.7211133 , 0.56337297, 0.64294016, 0.7929212 ,\n",
       "        0.2393992 , 0.286366  , 0.65253425, 0.3779497 , 0.42921388,\n",
       "        0.97239196, 0.9727074 , 0.2351495 , 0.3723421 , 0.21749103,\n",
       "        0.8454287 , 0.09347403, 0.09907067, 0.18151736, 0.3659029 ,\n",
       "        0.57383704, 0.82786894],\n",
       "       [0.9674777 , 0.65574443, 0.74517643, 0.2766713 , 0.2562008 ,\n",
       "        0.20931995, 0.33084738, 0.08820558, 0.28254807, 0.45649433,\n",
       "        0.94865894, 0.48325884, 0.48603272, 0.16754198, 0.07113492,\n",
       "        0.48526108, 0.49040353, 0.70369935, 0.6900282 , 0.10839856,\n",
       "        0.26474297, 0.62299013, 0.6046766 , 0.15504134, 0.5311502 ,\n",
       "        0.08772635, 0.8247328 , 0.09533548, 0.7796409 , 0.11835635,\n",
       "        0.25988925, 0.36526108],\n",
       "       [0.19458663, 0.9729527 , 0.05688155, 0.25083888, 0.8959205 ,\n",
       "        0.20137107, 0.36014676, 0.40657783, 0.3504815 , 0.10157347,\n",
       "        0.0553118 , 0.01374054, 0.10704362, 0.17213488, 0.737563  ,\n",
       "        0.25571728, 0.713313  , 0.02367115, 0.48557496, 0.07913792,\n",
       "        0.31333375, 0.6834034 , 0.82116556, 0.66593325, 0.54770756,\n",
       "        0.7349824 , 0.25683665, 0.60170996, 0.82831764, 0.88351214,\n",
       "        0.8711717 , 0.56177115],\n",
       "       [0.6432482 , 0.4972341 , 0.4974283 , 0.74463665, 0.41450512,\n",
       "        0.98299456, 0.46391892, 0.804783  , 0.00656354, 0.48764586,\n",
       "        0.61532533, 0.79547644, 0.6401795 , 0.20804012, 0.50054944,\n",
       "        0.2560588 , 0.52273023, 0.41551483, 0.9618741 , 0.8481481 ,\n",
       "        0.602299  , 0.29162836, 0.7187766 , 0.6171535 , 0.68187857,\n",
       "        0.5495795 , 0.61854446, 0.807431  , 0.78146887, 0.6727823 ,\n",
       "        0.80652726, 0.3194027 ],\n",
       "       [0.82620454, 0.73172104, 0.77887106, 0.90769756, 0.6377975 ,\n",
       "        0.7232213 , 0.5910604 , 0.0578537 , 0.11549044, 0.0592736 ,\n",
       "        0.3312676 , 0.20007491, 0.43665004, 0.85400784, 0.57587504,\n",
       "        0.6879145 , 0.77208734, 0.18016994, 0.58850217, 0.2689309 ,\n",
       "        0.8592932 , 0.82161236, 0.7397634 , 0.3306533 , 0.43327022,\n",
       "        0.7041595 , 0.98491967, 0.6303004 , 0.14005613, 0.6700535 ,\n",
       "        0.46920955, 0.94942474],\n",
       "       [0.54372907, 0.6584281 , 0.52767396, 0.35176134, 0.10037422,\n",
       "        0.5366857 , 0.5980419 , 0.13988256, 0.10009098, 0.2890805 ,\n",
       "        0.84151244, 0.07881796, 0.17885625, 0.41286254, 0.47467005,\n",
       "        0.36332572, 0.6101074 , 0.6856978 , 0.9606235 , 0.7725344 ,\n",
       "        0.73212254, 0.45587075, 0.65633   , 0.87107956, 0.12134421,\n",
       "        0.75422597, 0.7105447 , 0.62133324, 0.62727594, 0.32179487,\n",
       "        0.02598   , 0.16120446],\n",
       "       [0.62408614, 0.5700946 , 0.9456359 , 0.48375714, 0.40216672,\n",
       "        0.21878219, 0.97165525, 0.7370677 , 0.3067392 , 0.67569697,\n",
       "        0.4681964 , 0.7004839 , 0.3630234 , 0.7281791 , 0.72759736,\n",
       "        0.9150734 , 0.00559056, 0.35591567, 0.9440603 , 0.40453136,\n",
       "        0.12143409, 0.922413  , 0.8892518 , 0.7657088 , 0.5406549 ,\n",
       "        0.04460073, 0.9308208 , 0.36979103, 0.2827927 , 0.26353884,\n",
       "        0.82834387, 0.1931479 ]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 64), dtype=float32, numpy=\n",
       "array([[0.46018174, 0.04378627, 0.        , 0.        , 0.        ,\n",
       "        0.42299438, 0.34523797, 0.        , 0.        , 0.12637489,\n",
       "        0.        , 0.        , 0.        , 0.41921455, 0.        ,\n",
       "        0.2914696 , 0.5749398 , 0.        , 0.77925515, 0.17308937,\n",
       "        0.40170705, 0.06398591, 0.        , 0.63443774, 0.6560203 ,\n",
       "        0.21986024, 0.3344061 , 0.4382151 , 0.21859968, 0.        ,\n",
       "        0.        , 0.57530755, 0.        , 0.        , 0.5708516 ,\n",
       "        0.1341946 , 0.3219872 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.40437174, 0.        , 0.        ,\n",
       "        0.44575614, 0.2270598 , 0.18034655, 1.0233651 , 0.17806147,\n",
       "        0.        , 0.08093295, 0.6279463 , 0.02774907, 0.14967503,\n",
       "        0.29047564, 0.        , 0.08493026, 0.18763764, 0.        ,\n",
       "        0.        , 0.38196874, 0.13211797, 0.16025399],\n",
       "       [0.        , 0.2411018 , 0.        , 0.11416762, 0.        ,\n",
       "        0.18567844, 0.13139638, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.81324375, 0.1977177 , 0.        , 0.6562462 , 0.        ,\n",
       "        0.46112466, 0.        , 0.        , 0.94350314, 0.50563675,\n",
       "        0.        , 0.54411185, 0.        , 0.40866157, 0.0734298 ,\n",
       "        0.        , 0.36545846, 0.        , 0.00924771, 0.6373988 ,\n",
       "        0.377581  , 0.23077743, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11550537, 0.        , 0.        , 0.        ,\n",
       "        0.3220852 , 0.17610455, 0.        , 1.1231543 , 0.02515266,\n",
       "        0.20188144, 0.        , 0.51907456, 0.17378673, 0.2128882 ,\n",
       "        0.576747  , 0.0147231 , 0.        , 0.22590801, 0.        ,\n",
       "        0.        , 0.03989134, 0.        , 0.18614875],\n",
       "       [0.43841043, 0.23117097, 0.        , 0.        , 0.03159449,\n",
       "        0.46948883, 0.03321222, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01083355, 0.5392211 , 0.        ,\n",
       "        0.03701238, 1.001399  , 0.1287916 , 0.46801642, 0.01801441,\n",
       "        0.2785947 , 0.        , 0.        , 0.45742467, 0.36295015,\n",
       "        0.44885704, 0.1245745 , 0.10885318, 0.25379738, 0.        ,\n",
       "        0.        , 0.15843281, 0.        , 0.13672143, 0.6742784 ,\n",
       "        0.24991202, 0.13856806, 0.11878446, 0.        , 0.        ,\n",
       "        0.        , 0.34238213, 0.06101444, 0.        , 0.23861372,\n",
       "        0.1368555 , 0.4935316 , 0.        , 0.6557719 , 0.        ,\n",
       "        0.        , 0.        , 0.61302155, 0.22610983, 0.12956843,\n",
       "        0.5086682 , 0.        , 0.        , 0.1632709 , 0.        ,\n",
       "        0.        , 0.1502549 , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.01508777, 0.        ,\n",
       "        0.29621157, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.04728723, 0.4979977 , 0.04509357,\n",
       "        0.20097232, 0.7187946 , 0.        , 0.7844664 , 0.        ,\n",
       "        0.14899647, 0.31637   , 0.        , 0.6463406 , 0.08742281,\n",
       "        0.        , 0.5130762 , 0.        , 0.41522494, 0.5219164 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.32111427,\n",
       "        0.45404115, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.08948652, 0.52224433, 0.        , 0.10941448,\n",
       "        0.27145106, 0.13520996, 0.08729901, 0.4508286 , 0.        ,\n",
       "        0.        , 0.        , 1.0579544 , 0.23086038, 0.35796434,\n",
       "        0.04335408, 0.        , 0.        , 0.18830755, 0.        ,\n",
       "        0.        , 0.16196632, 0.        , 0.09548756],\n",
       "       [0.271068  , 0.04351043, 0.22778995, 0.        , 0.        ,\n",
       "        1.0842866 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12563528, 0.67320746, 0.12396445,\n",
       "        0.47740713, 1.1818268 , 0.        , 0.80094135, 0.38154718,\n",
       "        0.742707  , 0.00698506, 0.        , 0.5256753 , 0.2230941 ,\n",
       "        0.2201419 , 0.27448457, 0.        , 0.09444851, 0.        ,\n",
       "        0.        , 0.5934816 , 0.        , 0.        , 0.5410057 ,\n",
       "        0.40269724, 0.26310727, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12195633, 0.        , 0.        ,\n",
       "        0.5379843 , 0.14038248, 0.02462306, 1.3127027 , 0.1203358 ,\n",
       "        0.        , 0.15829216, 0.78328246, 0.01384932, 0.31437832,\n",
       "        0.62105733, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00465216],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30358344, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00157295, 0.64687544, 0.        ,\n",
       "        0.53345054, 0.9396783 , 0.        , 0.91097283, 0.04589215,\n",
       "        0.4711874 , 0.        , 0.12722884, 0.15093331, 0.8065435 ,\n",
       "        0.        , 0.59476316, 0.        , 0.        , 0.11154346,\n",
       "        0.07586499, 0.5175455 , 0.        , 0.        , 0.3734838 ,\n",
       "        0.37440974, 0.        , 0.        , 0.        , 0.500231  ,\n",
       "        0.        , 0.        , 0.20472436, 0.        , 0.13354842,\n",
       "        0.42011404, 0.3449413 , 0.4642906 , 0.7083334 , 0.29255107,\n",
       "        0.        , 0.        , 0.8348522 , 0.13719794, 0.10912501,\n",
       "        0.50584245, 0.        , 0.        , 0.08797646, 0.        ,\n",
       "        0.        , 0.04353882, 0.        , 0.        ],\n",
       "       [0.1815273 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5699503 , 0.19825158, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5217229 , 0.        ,\n",
       "        0.36626744, 0.8684639 , 0.        , 0.434565  , 0.13120425,\n",
       "        0.08257903, 0.        , 0.        , 0.51892895, 0.6641061 ,\n",
       "        0.5003669 , 0.19176294, 0.06048959, 0.        , 0.        ,\n",
       "        0.        , 0.2854392 , 0.        , 0.03191434, 0.6698357 ,\n",
       "        0.37815186, 0.21881138, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.06592561, 0.29577667, 0.        , 0.21771513,\n",
       "        0.3552641 , 0.20991167, 0.03385408, 1.3140979 , 0.        ,\n",
       "        0.        , 0.        , 0.5063151 , 0.37491253, 0.25212282,\n",
       "        0.3818963 , 0.        , 0.        , 0.2502645 , 0.        ,\n",
       "        0.        , 0.49746388, 0.3507389 , 0.00299794],\n",
       "       [0.33828175, 0.30675074, 0.18947494, 0.        , 0.        ,\n",
       "        0.66904885, 0.        , 0.        , 0.03179653, 0.20348182,\n",
       "        0.        , 0.        , 0.        , 0.45222855, 0.12857594,\n",
       "        0.65273356, 1.1262398 , 0.        , 1.1305764 , 0.        ,\n",
       "        0.1935313 , 0.08480354, 0.        , 0.5433932 , 0.40668902,\n",
       "        0.        , 0.50750726, 0.        , 0.24282378, 0.04284519,\n",
       "        0.        , 0.5737782 , 0.        , 0.5201699 , 0.18444735,\n",
       "        0.3698708 , 0.18393423, 0.        , 0.        , 0.07341664,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16909666,\n",
       "        0.        , 0.27681303, 0.        , 0.8166273 , 0.283594  ,\n",
       "        0.        , 0.        , 0.62192446, 0.38740936, 0.26855302,\n",
       "        0.12617773, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10478629]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KerasTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sq/47y8fpks7dvcphmgjk813k100000gn/T/ipykernel_69450/860286135.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'KerasTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "input_layer(sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "454033cece061eb073bcafc12f746a22f5b93635944b53d0919197e8924f3a7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
